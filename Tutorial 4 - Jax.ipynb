{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f2/gq8xgm9x491cqwtct_tgpy0h0000gn/T/ipykernel_15123/316186734.py:17: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  set_matplotlib_formats('svg', 'pdf') # For export\n"
     ]
    }
   ],
   "source": [
    "## Standard libraries\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import copy\n",
    "from typing import Any, Sequence, Callable, NamedTuple, Optional, Tuple\n",
    "PyTree = Any  # Type definition for PyTree, for readability\n",
    "from copy import deepcopy\n",
    "import pickle\n",
    "\n",
    "## Imports for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "%matplotlib inline\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg', 'pdf') # For export\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "## Progress bar\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "## JAX\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "from jax.tree_util import tree_map\n",
    "# Seeding for random operations\n",
    "main_rng = random.PRNGKey(42)\n",
    "\n",
    "## Flax (NN in JAX)\n",
    "try:\n",
    "    import flax\n",
    "except ModuleNotFoundError: # Install flax if missing\n",
    "    !pip install --quiet flax\n",
    "    import flax\n",
    "from flax import linen as nn\n",
    "from flax.training import train_state, checkpoints\n",
    "\n",
    "## Optax (Optimizers in JAX)\n",
    "try:\n",
    "    import optax\n",
    "except ModuleNotFoundError: # Install optax if missing\n",
    "    !pip install --quiet optax\n",
    "    import optax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: METAL:0\n"
     ]
    }
   ],
   "source": [
    "# Path to the folder where the datasets are/should be downloaded (e.g. MNIST)\n",
    "DATASET_PATH = \"../../data\"\n",
    "# Path to the folder where the pretrained models are saved\n",
    "CHECKPOINT_PATH = \"../../saved_models/tutorial4_jax\"\n",
    "\n",
    "# Verifying the device that will be used throughout this notebook\n",
    "print(\"Device:\", jax.devices()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/phlippe/saved_models/main/JAX/tutorial4/FashionMNIST_SGD.config...\n",
      "Downloading https://raw.githubusercontent.com/phlippe/saved_models/main/JAX/tutorial4/FashionMNIST_SGD_results.json...\n",
      "Downloading https://raw.githubusercontent.com/phlippe/saved_models/main/JAX/tutorial4/FashionMNIST_SGD.tar...\n",
      "Downloading https://raw.githubusercontent.com/phlippe/saved_models/main/JAX/tutorial4/FashionMNIST_SGDMom.config...\n",
      "Downloading https://raw.githubusercontent.com/phlippe/saved_models/main/JAX/tutorial4/FashionMNIST_SGDMom_results.json...\n",
      "Downloading https://raw.githubusercontent.com/phlippe/saved_models/main/JAX/tutorial4/FashionMNIST_SGDMom.tar...\n",
      "Downloading https://raw.githubusercontent.com/phlippe/saved_models/main/JAX/tutorial4/FashionMNIST_Adam.config...\n",
      "Downloading https://raw.githubusercontent.com/phlippe/saved_models/main/JAX/tutorial4/FashionMNIST_Adam_results.json...\n",
      "Downloading https://raw.githubusercontent.com/phlippe/saved_models/main/JAX/tutorial4/FashionMNIST_Adam.tar...\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "from urllib.error import HTTPError\n",
    "# Github URL where saved models are stored for this tutorial\n",
    "base_url = \"https://raw.githubusercontent.com/phlippe/saved_models/main/JAX/tutorial4/\"\n",
    "# Files to download\n",
    "pretrained_files = [\"FashionMNIST_SGD.config\",    \"FashionMNIST_SGD_results.json\",    \"FashionMNIST_SGD.tar\",\n",
    "                    \"FashionMNIST_SGDMom.config\", \"FashionMNIST_SGDMom_results.json\", \"FashionMNIST_SGDMom.tar\",\n",
    "                    \"FashionMNIST_Adam.config\",   \"FashionMNIST_Adam_results.json\",   \"FashionMNIST_Adam.tar\"   ]\n",
    "# Create checkpoint path if it doesn't exist yet\n",
    "os.makedirs(CHECKPOINT_PATH, exist_ok=True)\n",
    "\n",
    "# For each file, check whether it already exists. If not, try downloading it.\n",
    "for file_name in pretrained_files:\n",
    "    file_path = os.path.join(CHECKPOINT_PATH, file_name)\n",
    "    if not os.path.isfile(file_path):\n",
    "        file_url = base_url + file_name\n",
    "        print(f\"Downloading {file_url}...\")\n",
    "        try:\n",
    "            urllib.request.urlretrieve(file_url, file_path)\n",
    "        except HTTPError as e:\n",
    "            print(\"Something went wrong. Please try to download the file from the GDrive folder, or contact the author with the full output including the following error:\\n\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data as data\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision import transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformations applied on each image => bring them into a numpy array and normalize to mean 0 and std 1\n",
    "def image_to_numpy(img):\n",
    "    img = np.array(img, dtype=np.float32)\n",
    "    img = (img / 255. - 0.2861) / 0.3530\n",
    "    return img\n",
    "\n",
    "# We need to stack the batch elements as numpy arrays\n",
    "def numpy_collate(batch):\n",
    "    if isinstance(batch[0], np.ndarray):\n",
    "        return np.stack(batch)\n",
    "    elif isinstance(batch[0], (tuple,list)):\n",
    "        transposed = zip(*batch)\n",
    "        return [numpy_collate(samples) for samples in transposed]\n",
    "    else:\n",
    "        return np.array(batch)\n",
    "\n",
    "# Loading the training dataset. We need to split it into a training and validation part\n",
    "train_dataset = FashionMNIST(root=DATASET_PATH,\n",
    "                             train=True,\n",
    "                             transform=image_to_numpy,\n",
    "                             download=True)\n",
    "train_set, val_set = torch.utils.data.random_split(train_dataset,\n",
    "                                                   [50000, 10000],\n",
    "                                                   generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "# Loading the test set\n",
    "test_set = FashionMNIST(root=DATASET_PATH,\n",
    "                        train=False,\n",
    "                        transform=image_to_numpy,\n",
    "                        download=True)\n",
    "\n",
    "# We define a set of data loaders that we can use for various purposes later.\n",
    "# Note that for actually training a model, we will use different data loaders\n",
    "# with a lower batch size.\n",
    "train_loader = data.DataLoader(train_set,\n",
    "                               batch_size=1024,\n",
    "                               shuffle=False,\n",
    "                               drop_last=False,\n",
    "                               collate_fn=numpy_collate)\n",
    "val_loader   = data.DataLoader(val_set,\n",
    "                               batch_size=1024,\n",
    "                               shuffle=False,\n",
    "                               drop_last=False,\n",
    "                               collate_fn=numpy_collate)\n",
    "test_loader  = data.DataLoader(test_set,\n",
    "                               batch_size=1024,\n",
    "                               shuffle=False,\n",
    "                               drop_last=False,\n",
    "                               collate_fn=numpy_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean 0.28604060411453247\n",
      "Std 0.3530242443084717\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean\", (train_dataset.data.float() / 255.0).mean().item())\n",
    "print(\"Std\", (train_dataset.data.float() / 255.0).std().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.008\n",
      "Standard deviation: 1.009\n",
      "Maximum: 2.022\n",
      "Minimum: -0.810\n"
     ]
    }
   ],
   "source": [
    "imgs, _ = next(iter(train_loader))\n",
    "print(f\"Mean: {imgs.mean().item():5.3f}\")\n",
    "print(f\"Standard deviation: {imgs.std().item():5.3f}\")\n",
    "print(f\"Maximum: {imgs.max().item():5.3f}\")\n",
    "print(f\"Minimum: {imgs.min().item():5.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
