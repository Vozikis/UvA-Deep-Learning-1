{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f2/gq8xgm9x491cqwtct_tgpy0h0000gn/T/ipykernel_3079/3916073776.py:13: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  set_matplotlib_formats('svg', 'pdf') # For export\n"
     ]
    }
   ],
   "source": [
    "## Standard libraries\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "## Imports for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "%matplotlib inline\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg', 'pdf') # For export\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "## Progress bar\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "## PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device mps\n"
     ]
    }
   ],
   "source": [
    "# Path to the folder where the datasets are/should be downloaded (e.g. MNIST)\n",
    "DATASET_PATH = \"../data\"\n",
    "# Path to the folder where the pretrained models are saved\n",
    "CHECKPOINT_PATH = \"../saved_models/tutorial4\"\n",
    "\n",
    "# Function for setting the seed\n",
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "set_seed(42)\n",
    "\n",
    "\n",
    "\n",
    "# Fetching the device that will be used throughout this notebook\n",
    "device = torch.device(\"mps\") \n",
    "print(\"Using device\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from urllib.error import HTTPError\n",
    "# Github URL where saved models are stored for this tutorial\n",
    "base_url = \"https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial4/\"\n",
    "# Files to download\n",
    "pretrained_files = [\"FashionMNIST_SGD.config\",    \"FashionMNIST_SGD_results.json\",    \"FashionMNIST_SGD.tar\",\n",
    "                    \"FashionMNIST_SGDMom.config\", \"FashionMNIST_SGDMom_results.json\", \"FashionMNIST_SGDMom.tar\",\n",
    "                    \"FashionMNIST_Adam.config\",   \"FashionMNIST_Adam_results.json\",   \"FashionMNIST_Adam.tar\"   ]\n",
    "# Create checkpoint path if it doesn't exist yet\n",
    "os.makedirs(CHECKPOINT_PATH, exist_ok=True)\n",
    "\n",
    "# For each file, check whether it already exists. If not, try downloading it.\n",
    "for file_name in pretrained_files:\n",
    "    file_path = os.path.join(CHECKPOINT_PATH, file_name)\n",
    "    if not os.path.isfile(file_path):\n",
    "        file_url = base_url + file_name\n",
    "        print(f\"Downloading {file_url}...\")\n",
    "        try:\n",
    "            urllib.request.urlretrieve(file_url, file_path)\n",
    "        except HTTPError as e:\n",
    "            print(\"Something went wrong. Please try to download the file from the GDrive folder, or contact the author with the full output including the following error:\\n\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision import transforms\n",
    "\n",
    "# Transformations applied on each image => first make them a tensor, then normalize them with mean 0 and std 1\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.2861,), (0.3530,))\n",
    "                               ])\n",
    "\n",
    "# Loading the training dataset. We need to split it into a training and validation part\n",
    "train_dataset = FashionMNIST(root=DATASET_PATH, train=True, transform=transform, download=True)\n",
    "train_set, val_set = torch.utils.data.random_split(train_dataset, [50000, 10000])\n",
    "\n",
    "# Loading the test set\n",
    "test_set = FashionMNIST(root=DATASET_PATH, train=False, transform=transform, download=True)\n",
    "\n",
    "# We define a set of data loaders that we can use for various purposes later.\n",
    "# Note that for actually training a model, we will use different data loaders\n",
    "# with a lower batch size.\n",
    "train_loader = data.DataLoader(train_set, batch_size=1024, shuffle=True, drop_last=False)\n",
    "val_loader = data.DataLoader(val_set, batch_size=1024, shuffle=False, drop_last=False)\n",
    "test_loader = data.DataLoader(test_set, batch_size=1024, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean 0.28604060411453247\n",
      "Std 0.3530242443084717\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean\", (train_dataset.data.float() / 255.0).mean().item())\n",
    "print(\"Std\", (train_dataset.data.float() / 255.0).std().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.020\n",
      "Standard deviation: 1.011\n",
      "Maximum: 2.022\n",
      "Minimum: -0.810\n"
     ]
    }
   ],
   "source": [
    "imgs, _ = next(iter(train_loader))\n",
    "print(f\"Mean: {imgs.mean().item():5.3f}\")\n",
    "print(f\"Standard deviation: {imgs.std().item():5.3f}\")\n",
    "print(f\"Maximum: {imgs.max().item():5.3f}\")\n",
    "print(f\"Minimum: {imgs.min().item():5.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseNetwork(nn.Module):\n",
    "\n",
    "    def __init__(self, act_fn, input_size=784, num_classes=10, hidden_sizes=[512, 256, 256, 128]):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            act_fn - Object of the activation function that should be used as non-linearity in the network.\n",
    "            input_size - Size of the input images in pixels\n",
    "            num_classes - Number of classes we want to predict\n",
    "            hidden_sizes - A list of integers specifying the hidden layer sizes in the NN\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # Create the network based on the specified hidden sizes\n",
    "        layers = []\n",
    "        layer_sizes = [input_size] + hidden_sizes\n",
    "        for layer_index in range(1, len(layer_sizes)):\n",
    "            layers += [nn.Linear(layer_sizes[layer_index-1], layer_sizes[layer_index]),\n",
    "                       act_fn]\n",
    "        layers += [nn.Linear(layer_sizes[-1], num_classes)]\n",
    "        self.layers = nn.ModuleList(layers) # A module list registers a list of modules as submodules (e.g. for parameters)\n",
    "\n",
    "        self.config = {\"act_fn\": act_fn.__class__.__name__, \"input_size\": input_size, \"num_classes\": num_classes, \"hidden_sizes\": hidden_sizes}\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        for l in self.layers:\n",
    "            x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Identity(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "act_fn_by_name = {\n",
    "    \"tanh\": nn.Tanh,\n",
    "    \"relu\": nn.ReLU,\n",
    "    \"identity\": Identity\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "\n",
    "def plot_dists(val_dict, color=\"C0\", xlabel=None, stat=\"count\", use_kde=True):\n",
    "    columns = len(val_dict)\n",
    "    fig, ax = plt.subplots(1, columns, figsize=(columns*3, 2.5))\n",
    "    fig_index = 0\n",
    "    for key in sorted(val_dict.keys()):\n",
    "        key_ax = ax[fig_index%columns]\n",
    "        sns.histplot(val_dict[key], ax=key_ax, color=color, bins=50, stat=stat,\n",
    "                     kde=use_kde and ((val_dict[key].max()-val_dict[key].min())>1e-8)) # Only plot kde if there is variance\n",
    "        key_ax.set_title(f\"{key} \" + (r\"(%i $\\to$ %i)\" % (val_dict[key].shape[1], val_dict[key].shape[0]) if len(val_dict[key].shape)>1 else \"\"))\n",
    "        if xlabel is not None:\n",
    "            key_ax.set_xlabel(xlabel)\n",
    "        fig_index += 1\n",
    "    fig.subplots_adjust(wspace=0.4)\n",
    "    return fig\n",
    "\n",
    "##############################################################\n",
    "\n",
    "def visualize_weight_distribution(model, color=\"C0\"):\n",
    "    weights = {}\n",
    "    for name, param in model.named_parameters():\n",
    "        if name.endswith(\".bias\"):\n",
    "            continue\n",
    "        key_name = f\"Layer {name.split('.')[1]}\"\n",
    "        weights[key_name] = param.detach().view(-1).cpu().numpy()\n",
    "\n",
    "    ## Plotting\n",
    "    fig = plot_dists(weights, color=color, xlabel=\"Weight vals\")\n",
    "    fig.suptitle(\"Weight distribution\", fontsize=14, y=1.05)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "##############################################################\n",
    "\n",
    "def visualize_gradients(model, color=\"C0\", print_variance=False):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        net - Object of class BaseNetwork\n",
    "        color - Color in which we want to visualize the histogram (for easier separation of activation functions)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    small_loader = data.DataLoader(train_set, batch_size=1024, shuffle=False)\n",
    "    imgs, labels = next(iter(small_loader))\n",
    "    imgs, labels = imgs.to(device), labels.to(device)\n",
    "\n",
    "    # Pass one batch through the network, and calculate the gradients for the weights\n",
    "    model.zero_grad()\n",
    "    preds = model(imgs)\n",
    "    loss = F.cross_entropy(preds, labels) # Same as nn.CrossEntropyLoss, but as a function instead of module\n",
    "    loss.backward()\n",
    "    # We limit our visualization to the weight parameters and exclude the bias to reduce the number of plots\n",
    "    grads = {name: params.grad.view(-1).cpu().clone().numpy() for name, params in model.named_parameters() if \"weight\" in name}\n",
    "    model.zero_grad()\n",
    "\n",
    "    ## Plotting\n",
    "    fig = plot_dists(grads, color=color, xlabel=\"Grad magnitude\")\n",
    "    fig.suptitle(\"Gradient distribution\", fontsize=14, y=1.05)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    if print_variance:\n",
    "        for key in sorted(grads.keys()):\n",
    "            print(f\"{key} - Variance: {np.var(grads[key])}\")\n",
    "\n",
    "##############################################################\n",
    "\n",
    "def visualize_activations(model, color=\"C0\", print_variance=False):\n",
    "    model.eval()\n",
    "    small_loader = data.DataLoader(train_set, batch_size=1024, shuffle=False)\n",
    "    imgs, labels = next(iter(small_loader))\n",
    "    imgs, labels = imgs.to(device), labels.to(device)\n",
    "\n",
    "    # Pass one batch through the network, and calculate the gradients for the weights\n",
    "    feats = imgs.view(imgs.shape[0], -1)\n",
    "    activations = {}\n",
    "    with torch.no_grad():\n",
    "        for layer_index, layer in enumerate(model.layers):\n",
    "            feats = layer(feats)\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                activations[f\"Layer {layer_index}\"] = feats.view(-1).detach().cpu().numpy()\n",
    "\n",
    "    ## Plotting\n",
    "    fig = plot_dists(activations, color=color, stat=\"density\", xlabel=\"Activation vals\")\n",
    "    fig.suptitle(\"Activation distribution\", fontsize=14, y=1.05)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    if print_variance:\n",
    "        for key in sorted(activations.keys()):\n",
    "            print(f\"{key} - Variance: {np.var(activations[key])}\")\n",
    "\n",
    "\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dfl_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
